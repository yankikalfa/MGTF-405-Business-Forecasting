{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MDNu41wuoMLm"
      ],
      "authorship_tag": "ABX9TyMF4/+oc6wgdZXL6QAxP3na",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yankikalfa/MGTF-405-Business-Forecasting/blob/main/Panel_Stock_Returns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "m-zBQ_oqc33N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a2KZGoeYHdT",
        "outputId": "a5ffb4a5-cd40-46fb-ebcc-8771debe404e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from tensorflow.keras.layers import Input, Dropout, BatchNormalization\n",
        "# from tensorflow.keras.models import Model\n",
        "# import keras_tuner as kt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Normalization\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "MN4pOTy3c6gS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/MGTF 405/gkx_merged.csv')\n",
        "df=df.iloc[:,1:]"
      ],
      "metadata": {
        "id": "scLaF9n9dD1G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this dataframe we collect data from the GKX(2020) paper and merge it with CRSP's Returns data. The variable \"permno\" is the firms unique identifier."
      ],
      "metadata": {
        "id": "_0VJKIBTe62E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['permno'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q28zUVu4d9lN",
        "outputId": "b63884b2-458d-4b66-9493-d69cab314456"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3366"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"DATE\" variable shows date in human readable form, the \"date_cat\" variable is date in terms of time periods. We will use the \"date_cat\" for looping."
      ],
      "metadata": {
        "id": "NDeio_XwfaBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min(df['DATE']), max(df['DATE'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_i_VaRcf4Ja",
        "outputId": "9b9e4753-5c0a-477f-ab4c-772f028e4a95"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1985-01-31', '2021-12-31')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(data=df,x='ret',kind='hist')\n",
        "plt.xlim((-1,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "j5JRbsx4f7wo",
        "outputId": "33ab8a69-465b-4f98-a44c-8e45f2022508"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Feature Matrix"
      ],
      "metadata": {
        "id": "MDNu41wuoMLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(np.array(df.drop(['permno','DATE','date_cat','sic2','ret'],axis=1).columns).reshape((47,2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jAv7S6bJoSGf",
        "outputId": "bbd4a69d-9c3a-4d16-da28-a780ccd8cf93"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  0                1\n",
              "0             mvel1             beta\n",
              "1            betasq            chmom\n",
              "2            dolvol          idiovol\n",
              "3            indmom            mom1m\n",
              "4             mom6m           mom12m\n",
              "5            mom36m       pricedelay\n",
              "6              turn           absacc\n",
              "7               acc              age\n",
              "8               agr               bm\n",
              "9             bm_ia         cashdebt\n",
              "10           cashpr              cfp\n",
              "11           cfp_ia          chatoia\n",
              "12           chcsho          chempia\n",
              "13            chinv           chpmia\n",
              "14          convind           currat\n",
              "15             depr             divi\n",
              "16             divo               dy\n",
              "17              egr               ep\n",
              "18              gma           grcapx\n",
              "19          grltnoa             herf\n",
              "20             hire           invest\n",
              "21              lev              lgr\n",
              "22           mve_ia         operprof\n",
              "23           orgcap       pchcapx_ia\n",
              "24        pchcurrat          pchdepr\n",
              "25    pchgm_pchsale         pchquick\n",
              "26  pchsale_pchinvt  pchsale_pchrect\n",
              "27  pchsale_pchxsga       pchsaleinv\n",
              "28           pctacc               ps\n",
              "29            quick               rd\n",
              "30           rd_mve          rd_sale\n",
              "31       realestate             roic\n",
              "32         salecash          saleinv\n",
              "33          salerec          secured\n",
              "34       securedind              sgr\n",
              "35              sin               sp\n",
              "36             tang               tb\n",
              "37           aeavol             cash\n",
              "38             chtx          cinvest\n",
              "39              ear            nincr\n",
              "40             roaq           roavol\n",
              "41             roeq             rsup\n",
              "42           stdacc            stdcf\n",
              "43               ms         baspread\n",
              "44              ill           maxret\n",
              "45           retvol       std_dolvol\n",
              "46         std_turn        zerotrade"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5fc15f24-d984-4a37-be44-ea3e5d858594\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mvel1</td>\n",
              "      <td>beta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>betasq</td>\n",
              "      <td>chmom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dolvol</td>\n",
              "      <td>idiovol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>indmom</td>\n",
              "      <td>mom1m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mom6m</td>\n",
              "      <td>mom12m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>mom36m</td>\n",
              "      <td>pricedelay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>turn</td>\n",
              "      <td>absacc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>acc</td>\n",
              "      <td>age</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>agr</td>\n",
              "      <td>bm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bm_ia</td>\n",
              "      <td>cashdebt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>cashpr</td>\n",
              "      <td>cfp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>cfp_ia</td>\n",
              "      <td>chatoia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>chcsho</td>\n",
              "      <td>chempia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>chinv</td>\n",
              "      <td>chpmia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>convind</td>\n",
              "      <td>currat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>depr</td>\n",
              "      <td>divi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>divo</td>\n",
              "      <td>dy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>egr</td>\n",
              "      <td>ep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>gma</td>\n",
              "      <td>grcapx</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>grltnoa</td>\n",
              "      <td>herf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>hire</td>\n",
              "      <td>invest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>lev</td>\n",
              "      <td>lgr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>mve_ia</td>\n",
              "      <td>operprof</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>orgcap</td>\n",
              "      <td>pchcapx_ia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>pchcurrat</td>\n",
              "      <td>pchdepr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>pchgm_pchsale</td>\n",
              "      <td>pchquick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>pchsale_pchinvt</td>\n",
              "      <td>pchsale_pchrect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>pchsale_pchxsga</td>\n",
              "      <td>pchsaleinv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>pctacc</td>\n",
              "      <td>ps</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>quick</td>\n",
              "      <td>rd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>rd_mve</td>\n",
              "      <td>rd_sale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>realestate</td>\n",
              "      <td>roic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>salecash</td>\n",
              "      <td>saleinv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>salerec</td>\n",
              "      <td>secured</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>securedind</td>\n",
              "      <td>sgr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>sin</td>\n",
              "      <td>sp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>tang</td>\n",
              "      <td>tb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>aeavol</td>\n",
              "      <td>cash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>chtx</td>\n",
              "      <td>cinvest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>ear</td>\n",
              "      <td>nincr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>roaq</td>\n",
              "      <td>roavol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>roeq</td>\n",
              "      <td>rsup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>stdacc</td>\n",
              "      <td>stdcf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>ms</td>\n",
              "      <td>baspread</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>ill</td>\n",
              "      <td>maxret</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>retvol</td>\n",
              "      <td>std_dolvol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>std_turn</td>\n",
              "      <td>zerotrade</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fc15f24-d984-4a37-be44-ea3e5d858594')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5fc15f24-d984-4a37-be44-ea3e5d858594 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5fc15f24-d984-4a37-be44-ea3e5d858594');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feed-Forward Neural Networks"
      ],
      "metadata": {
        "id": "kbHUNwAdjf9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose is to develop a neural network model which will take into account all stocks, and forecast all stocks in the dataframe."
      ],
      "metadata": {
        "id": "_AFIxmx2nw4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=df['ret']\n",
        "X=df.drop(['ret','DATE','sic2','permno'],axis=1)"
      ],
      "metadata": {
        "id": "_krNb4y8jmvo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)==len(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ7fF_BIptkD",
        "outputId": "a803468a-a610-4e9a-bb54-c88acc82cbcc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GKX show that a neural net with 3 hidden layer seem to perform best amongst the data tested. We will define a model with different potential hyperparamters."
      ],
      "metadata": {
        "id": "LzRoeerTtLMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import typing\n",
        "\n",
        "class SklearnWrapper:\n",
        "    def __init__(self, transformation: typing.Callable):\n",
        "        self.transformation = transformation\n",
        "        self._group_transforms = []\n",
        "        # Start with -1 and for each group up the pointer by one\n",
        "        self._pointer = -1\n",
        "\n",
        "    def _call_with_function(self, df: pd.DataFrame, function: str):\n",
        "        # If pointer >= len we are making a new apply, reset _pointer\n",
        "        if self._pointer >= len(self._group_transforms):\n",
        "            self._pointer = -1\n",
        "        self._pointer += 1\n",
        "        return pd.DataFrame(\n",
        "            getattr(self._group_transforms[self._pointer], function)(df.values),\n",
        "            columns=df.columns,\n",
        "            index=df.index,\n",
        "        )\n",
        "\n",
        "    def fit(self, df):\n",
        "        self._group_transforms.append(self.transformation.fit(df.values))\n",
        "        return self\n",
        "\n",
        "    def transform(self, df):\n",
        "        return self._call_with_function(df, \"transform\")\n",
        "\n",
        "    def fit_transform(self, df):\n",
        "        self.fit(df)\n",
        "        return self.transform(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "yvy0ma5yeA9t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalermin=SklearnWrapper(MinMaxScaler(feature_range=(-1,1)))"
      ],
      "metadata": {
        "id": "ebaypR3de5Xc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr=X.groupby('date_cat').apply(scalermin.fit_transform).drop(['date_cat'],axis=1)"
      ],
      "metadata": {
        "id": "QdfwYBoMezp6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr=pd.concat((x_tr,X['date_cat']),axis=1)"
      ],
      "metadata": {
        "id": "4N_R7pxWiorw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(X_tr['date_cat'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRfvS_y39yLB",
        "outputId": "3e7b97ed-1858-48fa-b537-a41da0229ee8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "779"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_tr[X_tr['date_cat']<=777].drop('date_cat',axis=1)\n",
        "X_val=X_tr[X_tr['date_cat']==778].drop('date_cat',axis=1)\n",
        "X_test=X_tr[X_tr['date_cat']==779].drop('date_cat',axis=1)"
      ],
      "metadata": {
        "id": "TEx-C5S0C-Lz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y[:204750]\n",
        "y_val=y[204750:205413]\n",
        "y_test=y[205413:]"
      ],
      "metadata": {
        "id": "g1OWI81FEGU_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new=pd.concat((X_train,X_val),axis=0)\n",
        "y_new=pd.concat((y_train,y_val),axis=0)"
      ],
      "metadata": {
        "id": "03uv23d8UWlv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the Patience Level of Early Stopping\n",
        "# Iterations increase with patience\n",
        "\n",
        "#patience =2\n",
        "#patience =3\n",
        "#patience =4\n",
        "#patience =5\n",
        "patience =6\n",
        "#patience =7\n",
        "#patience =8\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss',patience=patience)"
      ],
      "metadata": {
        "id": "iULDuyLBw0sQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict={}"
      ],
      "metadata": {
        "id": "kVYpBpCy1k2u"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def panel_deep_neuralnets(n1,n2,n3,loss,opt,act_fn,es=False):\n",
        "  prediction_train=[]\n",
        "  prediction_test=[]\n",
        "  oosr2=[]\n",
        "  if es:\n",
        "    normalizer=Normalization(axis=-1)\n",
        "    model=Sequential(normalizer)\n",
        "    model.add(Dense(n1,activation=act_fn))\n",
        "    model.add(Dense(n2,activation=act_fn))\n",
        "    model.add(Dense(n3,activation=act_fn))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss=loss,optimizer=opt)\n",
        "    model.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=200,callbacks=[early_stop])\n",
        "  else:\n",
        "    normalizer=Normalization(axis=-1)\n",
        "    model=Sequential(normalizer)\n",
        "    model.add(Dense(n1,activation=act_fn))\n",
        "    model.add(Dense(n2,activation=act_fn))\n",
        "    model.add(Dense(n3,activation=act_fn))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss=loss,optimizer=opt)\n",
        "    model.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=200)\n",
        "\n",
        "  prediction_train = model.predict(X_new)\n",
        "  prediction_test=model.predict(X_test)\n",
        "  benchmark=np.zeros\n",
        "  oosr2=1-(mean_squared_error(y_test,prediction_test)/mean_squared_error(y_test,pd.DataFrame(np.zeros(len(y_test)))))\n",
        "  output_dict['nn3'+'_['+str(n1)+'_'+str(n2)+'_'+str(n3)+'_'+loss+'_'+opt+'_'+act_fn+'_'+str(es)+']']={}\n",
        "  output_dict['nn3'+'_['+str(n1)+'_'+str(n2)+'_'+str(n3)+'_'+loss+'_'+opt+'_'+act_fn+'_'+str(es)+']']['In Sample Prediction']=prediction_train\n",
        "  output_dict['nn3'+'_['+str(n1)+'_'+str(n2)+'_'+str(n3)+'_'+loss+'_'+opt+'_'+act_fn+'_'+str(es)+']']['Forecast']=prediction_test\n",
        "  output_dict['nn3'+'_['+str(n1)+'_'+str(n2)+'_'+str(n3)+'_'+loss+'_'+opt+'_'+act_fn+'_'+str(es)+']']['OOSR2']=oosr2\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "1151ZxrRw_tc"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dict={}"
      ],
      "metadata": {
        "id": "Fdm49v6h3RPW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "panel_deep_neuralnets(32,16,8,'huber','adam','relu',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'huber','adam','sigmoid',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'huber','adam','selu',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'mean_squared_error','adam','relu',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'mean_squared_error','adam','sigmoid',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'mean_squared_error','adam','selu',es=True)\n",
        "\n",
        "panel_deep_neuralnets(32,16,8,'huber','adam','relu',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'huber','adam','sigmoid',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'huber','adam','selu',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'mean_squared_error','adam','relu',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'mean_squared_error','adam','sigmoid',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'mean_squared_error','adam','selu',es=True)\n",
        "\n",
        "panel_deep_neuralnets(32,16,8,'huber','ftrl','relu',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'huber','ftrl','sigmoid',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'huber','ftrl','selu',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'mean_squared_error','ftrl','relu',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'mean_squared_error','ftrl','sigmoid',es=True)\n",
        "panel_deep_neuralnets(32,16,8,'mean_squared_error','ftrl','selu',es=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27Ff8dM00s84",
        "outputId": "a4f67d51-417d-410e-ba6d-fd7901e728f8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 14s 2ms/step - loss: 0.0137 - val_loss: 0.0115\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0136 - val_loss: 0.0118\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 13s 2ms/step - loss: 0.0135 - val_loss: 0.0115\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0135 - val_loss: 0.0118\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 13s 2ms/step - loss: 0.0134 - val_loss: 0.0121\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0134 - val_loss: 0.0116\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 13s 2ms/step - loss: 0.0134 - val_loss: 0.0117\n",
            "Epoch 8/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0133 - val_loss: 0.0114\n",
            "Epoch 9/200\n",
            "6399/6399 [==============================] - 13s 2ms/step - loss: 0.0133 - val_loss: 0.0111\n",
            "Epoch 10/200\n",
            "6399/6399 [==============================] - 13s 2ms/step - loss: 0.0133 - val_loss: 0.0126\n",
            "Epoch 11/200\n",
            "6399/6399 [==============================] - 13s 2ms/step - loss: 0.0133 - val_loss: 0.0124\n",
            "Epoch 12/200\n",
            "6399/6399 [==============================] - 13s 2ms/step - loss: 0.0133 - val_loss: 0.0121\n",
            "Epoch 13/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0132 - val_loss: 0.0111\n",
            "Epoch 14/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0132 - val_loss: 0.0121\n",
            "Epoch 15/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0132 - val_loss: 0.0111\n",
            "Epoch 16/200\n",
            "6399/6399 [==============================] - 13s 2ms/step - loss: 0.0132 - val_loss: 0.0110\n",
            "Epoch 17/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0132 - val_loss: 0.0116\n",
            "Epoch 18/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0131 - val_loss: 0.0121\n",
            "Epoch 19/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0131 - val_loss: 0.0114\n",
            "Epoch 20/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0131 - val_loss: 0.0116\n",
            "Epoch 21/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0131 - val_loss: 0.0117\n",
            "Epoch 22/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0131 - val_loss: 0.0116\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0142 - val_loss: 0.0117\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0136 - val_loss: 0.0119\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 13s 2ms/step - loss: 0.0136 - val_loss: 0.0111\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0135 - val_loss: 0.0125\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0134 - val_loss: 0.0122\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0134 - val_loss: 0.0131\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 13s 2ms/step - loss: 0.0133 - val_loss: 0.0124\n",
            "Epoch 8/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0133 - val_loss: 0.0126\n",
            "Epoch 9/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0133 - val_loss: 0.0125\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0152 - val_loss: 0.0109\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0138 - val_loss: 0.0130\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0137 - val_loss: 0.0125\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0136 - val_loss: 0.0119\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0135 - val_loss: 0.0126\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0135 - val_loss: 0.0127\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0134 - val_loss: 0.0138\n",
            "6420/6420 [==============================] - 8s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0320 - val_loss: 0.0236\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0319 - val_loss: 0.0242\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0319 - val_loss: 0.0244\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0319 - val_loss: 0.0246\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0319 - val_loss: 0.0236\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0319 - val_loss: 0.0240\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0319 - val_loss: 0.0242\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0322 - val_loss: 0.0230\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0317 - val_loss: 0.0237\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0316 - val_loss: 0.0244\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0315 - val_loss: 0.0221\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0314 - val_loss: 0.0252\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0312 - val_loss: 0.0234\n",
            "Epoch 8/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0312 - val_loss: 0.0247\n",
            "Epoch 9/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0311 - val_loss: 0.0240\n",
            "Epoch 10/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0310 - val_loss: 0.0271\n",
            "Epoch 11/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0309 - val_loss: 0.0231\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0382 - val_loss: 0.0214\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0322 - val_loss: 0.0233\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0319 - val_loss: 0.0216\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0317 - val_loss: 0.0227\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0315 - val_loss: 0.0289\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0314 - val_loss: 0.0240\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0314 - val_loss: 0.0239\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0137 - val_loss: 0.0116\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0136 - val_loss: 0.0120\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0136 - val_loss: 0.0117\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0136 - val_loss: 0.0120\n",
            "Epoch 8/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0135 - val_loss: 0.0123\n",
            "Epoch 9/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0135 - val_loss: 0.0119\n",
            "Epoch 10/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0135 - val_loss: 0.0128\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0154 - val_loss: 0.0113\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0136 - val_loss: 0.0118\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0136 - val_loss: 0.0114\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0135 - val_loss: 0.0121\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0135 - val_loss: 0.0116\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0134 - val_loss: 0.0119\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0134 - val_loss: 0.0116\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0160 - val_loss: 0.0112\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0140 - val_loss: 0.0120\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0138 - val_loss: 0.0129\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0137 - val_loss: 0.0111\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0136 - val_loss: 0.0112\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0136 - val_loss: 0.0124\n",
            "Epoch 8/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0135 - val_loss: 0.0118\n",
            "Epoch 9/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0135 - val_loss: 0.0121\n",
            "Epoch 10/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0135 - val_loss: 0.0124\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0323 - val_loss: 0.0235\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0318 - val_loss: 0.0235\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0317 - val_loss: 0.0234\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0316 - val_loss: 0.0240\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0315 - val_loss: 0.0245\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0314 - val_loss: 0.0240\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0314 - val_loss: 0.0240\n",
            "Epoch 8/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0313 - val_loss: 0.0248\n",
            "Epoch 9/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0312 - val_loss: 0.0246\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0320 - val_loss: 0.0227\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0318 - val_loss: 0.0226\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0317 - val_loss: 0.0222\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0316 - val_loss: 0.0244\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0315 - val_loss: 0.0236\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0314 - val_loss: 0.0240\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0313 - val_loss: 0.0226\n",
            "Epoch 8/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0312 - val_loss: 0.0230\n",
            "Epoch 9/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0311 - val_loss: 0.0243\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0335 - val_loss: 0.0217\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0322 - val_loss: 0.0235\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0320 - val_loss: 0.0287\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0239\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0317 - val_loss: 0.0262\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0316 - val_loss: 0.0228\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0315 - val_loss: 0.0292\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 10s 1ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "6420/6420 [==============================] - 8s 1ms/step\n",
            "21/21 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 8/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 9/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 10/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 11/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 8/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0137 - val_loss: 0.0118\n",
            "6420/6420 [==============================] - 8s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 10s 1ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "Epoch 8/200\n",
            "6399/6399 [==============================] - 9s 1ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0329 - val_loss: 0.0237\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 10s 1ms/step - loss: 0.0319 - val_loss: 0.0239\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0239\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 10s 1ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0238\n",
            "6420/6420 [==============================] - 8s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0330 - val_loss: 0.0238\n",
            "Epoch 2/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0319 - val_loss: 0.0233\n",
            "Epoch 3/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0318 - val_loss: 0.0232\n",
            "Epoch 4/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0318 - val_loss: 0.0231\n",
            "Epoch 5/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0318 - val_loss: 0.0233\n",
            "Epoch 6/200\n",
            "6399/6399 [==============================] - 12s 2ms/step - loss: 0.0317 - val_loss: 0.0236\n",
            "Epoch 7/200\n",
            "6399/6399 [==============================] - 11s 2ms/step - loss: 0.0317 - val_loss: 0.0233\n",
            "Epoch 8/200\n",
            "6399/6399 [==============================] - 10s 1ms/step - loss: 0.0317 - val_loss: 0.0232\n",
            "Epoch 9/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0317 - val_loss: 0.0236\n",
            "Epoch 10/200\n",
            "6399/6399 [==============================] - 10s 2ms/step - loss: 0.0317 - val_loss: 0.0234\n",
            "6420/6420 [==============================] - 7s 1ms/step\n",
            "21/21 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "byxrIuYV-3eY"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('NN_output.pickle', 'wb') as handle:\n",
        "    pickle.dump(output_dict, handle, protocol=4)"
      ],
      "metadata": {
        "id": "Ura3VmVpImFI"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gV1t4XGvIr-D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}